{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb24c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, BadRequestError\n",
    "from openai.types.chat import ChatCompletion\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "import time\n",
    "from typing import Optional\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from openai import OpenAI\n",
    "import dataclasses\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6aec1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimumDelay:\n",
    "    def __init__(self, delay: float | int):\n",
    "        self.delay = delay\n",
    "        self.start = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        end = time.time()\n",
    "        seconds = end - self.start\n",
    "        if self.delay > seconds:\n",
    "            time.sleep(self.delay - seconds)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=90), stop=stop_after_attempt(3))\n",
    "def chat(client: OpenAI, delay: float | int, **kwargs) -> ChatCompletion | None:\n",
    "    try:\n",
    "        with MinimumDelay(delay):\n",
    "            return client.chat.completions.create(**kwargs)\n",
    "    except BadRequestError as e:\n",
    "        print(f\"Bad Request: {e}\")\n",
    "        if \"safety\" in e.message:\n",
    "            return None\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "        raise e\n",
    "def print_messages(messages):\n",
    "    for message in messages:\n",
    "        if isinstance(message[\"content\"], list):\n",
    "            print(f\"{message['role']}:\")\n",
    "            for content in message[\"content\"]:\n",
    "                if content[\"type\"] == \"text\":\n",
    "                    print(content[\"text\"])\n",
    "                elif content[\"type\"] == \"image_url\":\n",
    "                    print(\"[IMAGE]\")\n",
    "        else:\n",
    "            print(f\"{message['role']}: {message['content']}\")\n",
    "        print()\n",
    "    print(\"=========================================\")\n",
    "\n",
    "def read_jsonl(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                ex = json.loads(line)\n",
    "                yield ex\n",
    "\n",
    "def write_jsonl(path, data):\n",
    "    with open(path, \"w\") as f:\n",
    "        for ex in data:\n",
    "            f.write(json.dumps(ex) + \"\\n\")\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc86068",
   "metadata": {},
   "source": [
    "Step 1: HTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af111849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import instructor\n",
    "\n",
    "client = instructor.from_openai(OpenAI(api_key=os.environ['OPENAI_API_KEY'], timeout= 90))\n",
    "class InstructorChatCompletionConfig(BaseModel):\n",
    "    seed: int = Field(..., description=\"Random seed for reproducibility\")\n",
    "    delay: int = Field(..., description=\"Minimum delay between requests in seconds\")\n",
    "    model: str = Field(..., description=\"Model to use for chat completion\")\n",
    "    max_tokens: int = Field(..., description=\"Maximum number of tokens in the response\")\n",
    "    temperature: float = Field(..., description=\"Sampling temperature for response generation\")\n",
    "    system_prompt: str = Field(..., description=\"System prompt to set the context for the conversation\")\n",
    "    user_prompt: str = Field(..., description=\"User prompt to initiate the conversation\")\n",
    "    response_format: dict | None = Field(None, description=\"Expected format of the response\")\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    feedback: list[str] = Field(\n",
    "        description=\"A list of actions to take to make predicted values more consistent with the value taxonomy.\"\n",
    "    )\n",
    "    is_consistent: bool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f42620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Level1Value(BaseModel):\n",
    "    level_1_value: str = Field(\n",
    "        description=\"Level 1 Shwartz cultural value applicable to the frame.\",\n",
    "        enum=[\"Openness to Change\", \"Self-Enhancement\", \"Conservation\", \"Self-Transcendence\"]\n",
    "    )\n",
    "    rationale: str = Field(description=\"Rationale explaining why the level 1 value is applicable to the frame.\")\n",
    "\n",
    "\n",
    "class Level2Value(BaseModel):\n",
    "    level_2_value: str = Field(\n",
    "        description=\"Level 2 cultural value applicable to the frame.\",\n",
    "        enum=[\n",
    "            \"Self-direction (thought)\",\n",
    "            \"Self-direction (action)\",\n",
    "            \"Stimulation\",\n",
    "            \"Hedonism\",\n",
    "            \"Achievement\",\n",
    "            \"Power (dominance)\",\n",
    "            \"Power (resources)\",\n",
    "            \"Face\",\n",
    "            \"Security (personal)\",\n",
    "            \"Security (societal)\",\n",
    "            \"Tradition\",\n",
    "            \"Conformity (rules)\",\n",
    "            \"Conformity (interpersonal)\",\n",
    "            \"Humility\",\n",
    "            \"Benevolence (caring)\",\n",
    "            \"Benevolence (dependability)\",\n",
    "            \"Universalism (concern)\",\n",
    "            \"Universalism (nature)\",\n",
    "            \"Universalism (tolerance)\",\n",
    "            \"Universalism (objectivity)\"\n",
    "        ]\n",
    "    )\n",
    "    rationale: str = Field(description=\"Rationale explaining why the level 2 value is applicable to the frame.\")\n",
    "\n",
    "\n",
    "class Level3Value(BaseModel):\n",
    "    level_3_value: str = Field(description=\"Level 3 cultural value applicable to the frame.\")\n",
    "    rationale: str = Field(description=\"Rationale explaining why the level 3 value is applicable to the frame.\")\n",
    "\n",
    "\n",
    "class Values(BaseModel):\n",
    "    level_1_values: List[Level1Value] = Field(..., alias=\"level 1 values\")\n",
    "    level_2_values: List[Level2Value] = Field(..., alias=\"level 2 values\")\n",
    "    level_3_values: List[Level3Value] = Field(..., alias=\"level 3 values\")\n",
    "\n",
    "\n",
    "class CulturalValues(BaseModel):\n",
    "    values: Values\n",
    "\n",
    "class Timestep(BaseModel):\n",
    "    response: CulturalValues\n",
    "    feedback: Optional[list[str]] = Field(default_factory=list)\n",
    "    refined_response: Optional[CulturalValues]\n",
    "\n",
    "\n",
    "class History(BaseModel):\n",
    "    history: list[Timestep] = Field(default_factory=list)\n",
    "\n",
    "    def add(self, code, feedback, refined_code):\n",
    "        self.history.append(\n",
    "            Timestep(response=code, feedback=feedback, refined_response=refined_code)\n",
    "        )\n",
    "def stop_condition(feedback, history):\n",
    "    return feedback.is_consistent or len(history.history) >= 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea9fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = 'prompts/hierarchical.yaml'\n",
    "with open(config_file_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    config = InstructorChatCompletionConfig(**config)\n",
    "\n",
    "with open('prompts/feedback.yaml', 'r') as f:\n",
    "    feedback_config = yaml.safe_load(f)\n",
    "    feedback_config = InstructorChatCompletionConfig(**feedback_config)\n",
    "\n",
    "with open('prompts/refine.yaml', 'r') as f:\n",
    "    refine_config = yaml.safe_load(f)\n",
    "    refine_config = InstructorChatCompletionConfig(**refine_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ea01809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_level2_actions(level1_action: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Get valid level 2 actions based on the level 1 action.\n",
    "    \"\"\"\n",
    "    if level1_action == \"Openness to Change\":\n",
    "        return[\"Self-direction (thought)\",\n",
    "                      \"Self-direction (action)\",\n",
    "                      \"Stimulation\",\n",
    "                      \"Hedonism\"]   \n",
    "                    \n",
    "    elif level1_action == \"Self-Enhancement\":\n",
    "        return [\"Hedonism\", \"Achievement\",\n",
    "                      \"Power (dominance)\",\n",
    "                      \"Power (resources)\", \"Face\"]\n",
    "    elif level1_action == \"Conservation\":\n",
    "        return [\"Face\",\"Security (personal)\",\n",
    "                      \"Security (societal)\",\n",
    "                      \"Tradition\",\n",
    "                      \"Conformity (rules)\",  \n",
    "                      \"Conformity (interpersonal)\",\n",
    "                      \"Humility\"]\n",
    "    elif level1_action == \"Self-Transcendence\":\n",
    "        return [\"Humility\", \"Benevolence (caring)\",\n",
    "                \"Benevolence (dependability)\",\n",
    "                      \"Universalism (concern)\",\n",
    "                      \"Universalism (nature)\",\n",
    "                      \"Universalism (tolerance)\"\n",
    "                      \"Universalism (objectivity)\"]\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def get_valid_level3_actions(level2_action: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Get valid level 3 actions based on the level 2 action.\n",
    "    \"\"\"\n",
    "    if level2_action == \"Self-direction (thought)\":\n",
    "        return [\"Be creative\",\n",
    "                \"Be curious\",\n",
    "                \"Have freedom of thought\",]\n",
    "    elif level2_action == \"Self-direction (action)\":\n",
    "        return [\"Be choosing your own goals\",\n",
    "                \"Be independent\",\n",
    "                \"Have freedom of action\",\"Have privacy\"]\n",
    "    elif level2_action == \"Stimulation\":\n",
    "        return [\"Have an exciting life\",\n",
    "                \"Have a varied life\",\n",
    "                \"Be daring\",]\n",
    "    elif level2_action == \"Hedonism\":\n",
    "        return [\"Have pleasure\"]\n",
    "    elif level2_action == \"Achievement\":\n",
    "        return [\"Be ambitious\",\n",
    "                \"Have success\"\n",
    "                \"Be capable\",\n",
    "                \"Be intellectual\",\n",
    "                \"Be courageous\"]\n",
    "    elif level2_action == \"Power (dominance)\":\n",
    "        return [\"Have influence\",\n",
    "                \"Have the right to command\"]\n",
    "    elif level2_action == \"Power (resources)\":\n",
    "        return [\"Have wealth\"]\n",
    "    elif level2_action == \"Face\":\n",
    "        return [\"Have a social recognition\",\n",
    "                \"Have a good reputation\",\n",
    "        ]\n",
    "    elif level2_action == \"Security (personal)\":\n",
    "        return [\"Have a sense of belonging\",\n",
    "                \"Have good health\",\n",
    "                \"Have no debts\",\n",
    "                \"Be neat and tidy\",\n",
    "                \"Have a comfortable life\"]\n",
    "    elif level2_action == \"Security (societal)\":\n",
    "        return [\"Have a safe country\",\n",
    "                \"Have a stable society\",]\n",
    "    elif level2_action == \"Tradition\":\n",
    "        return [\"Be respecting traditions\",\n",
    "                \"Be holding religious faith\"]\n",
    "    elif level2_action == \"Conformity (rules)\":\n",
    "        return [\"Be compliant\",\n",
    "                \"Be self-disciplined\",\n",
    "                \"Be behaving properly\",]\n",
    "    elif level2_action == \"Conformity (interpersonal)\":\n",
    "        return [\"Be polite\",\n",
    "                \"Be honouring elders\",]\n",
    "    elif level2_action == \"Humility\":\n",
    "        return [\"Be humble\",\n",
    "                \"Have life accepted as is\"]\n",
    "    elif level2_action == \"Benevolence (caring)\":\n",
    "        return [\"Be helpful\",\n",
    "                \"Be honest\",\n",
    "                \"Be forgiving\",\n",
    "                \"Have the own family secured\",\n",
    "                \"Be loving\"]\n",
    "    elif level2_action == \"Benevolence (dependability)\":\n",
    "        return [\"Be responsible\",\n",
    "                \"Have loyalty towards friends\"]\n",
    "    elif level2_action == \"Universalism (concern)\":\n",
    "        return [\"Have equality\",\n",
    "                \"Be just\",\n",
    "                \"Have a world at peace\"]\n",
    "    elif level2_action == \"Universalism (nature)\":\n",
    "        return [\"Be protecting the environment\",\n",
    "                \"Have harmony with nature\",\n",
    "                \"Have a world of beauty\"]\n",
    "    elif level2_action == \"Universalism (tolerance)\":\n",
    "        return [\"Be broadminded\",\n",
    "                \"Have the wisdom to accept others\"]\n",
    "    \n",
    "    elif level2_action == \"Universalism (objectivity)\":\n",
    "        return [\"Be logical\",\n",
    "                \"Have an objective view\"]\n",
    "    else:\n",
    "        return []\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecefa552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(config: InstructorChatCompletionConfig, frame: str):\n",
    "    with open(\"cultural_values_taxonomy.yaml\", \"r\") as f:\n",
    "        values_yaml = f.read()\n",
    "\n",
    "    sys_prompt = config.system_prompt.strip()\n",
    "    user_prompt= config.user_prompt.strip()\n",
    "    final_sys_prompt=sys_prompt.format(values_yaml=values_yaml)\n",
    "    msg=[{\"role\": \"system\", \"content\": final_sys_prompt},\n",
    "         {\"role\": \"user\", \"content\": user_prompt.format(Frame=frame)}]\n",
    "    #print_messages(msg)\n",
    "    return client.chat.completions.create(\n",
    "        model=config.model,\n",
    "        messages=msg,\n",
    "        temperature=config.temperature,\n",
    "        response_model=CulturalValues,\n",
    "        seed=config.seed\n",
    "    )\n",
    "\n",
    "def get_levels_from_response(response: dict) -> dict:\n",
    "    level1_vals=[]\n",
    "    level1_rats=[]\n",
    "    level2_vals=[]\n",
    "    level2_rats=[]\n",
    "    level3_vals=[]\n",
    "    level3_rats=[]\n",
    "    for l in response.values.level_1_values:\n",
    "        level1_vals.append(l.level_1_value)\n",
    "        level1_rats.append(l.rationale)\n",
    "    for l in response.values.level_2_values:\n",
    "        level2_vals.append(l.level_2_value)\n",
    "        level2_rats.append(l.rationale)\n",
    "    for l in response.values.level_3_values:\n",
    "        level3_vals.append(l.level_3_value)\n",
    "        level3_rats.append(l.rationale)\n",
    "\n",
    "    app_level2_vals = []\n",
    "    seen = set()\n",
    "\n",
    "    for val in level1_vals:\n",
    "        for lvl2 in get_valid_level2_actions(val):\n",
    "            if lvl2 not in seen:\n",
    "                seen.add(lvl2)\n",
    "                app_level2_vals.append(lvl2)\n",
    "\n",
    "    app_level3_vals = []\n",
    "    seen = set()\n",
    "    for val in level2_vals:\n",
    "        for lvl3 in get_valid_level3_actions(val):\n",
    "            if lvl3 not in seen:\n",
    "                app_level3_vals.append(lvl3)\n",
    "                \n",
    "    return {\"level1_vals\": level1_vals, \"level1_rats\": level1_rats, \"level2_vals\": level2_vals, \"level2_rats\": level2_rats, \n",
    "            \"level3_vals\": level3_vals, \"level3_rats\": level3_rats, \"app_level2_vals\": app_level2_vals, \"app_level3_vals\": app_level3_vals}\n",
    "\n",
    "\n",
    "\n",
    "def generate_feedback(config:InstructorChatCompletionConfig, response: dict, frame: str):\n",
    "    sys_prompt = config.system_prompt.strip()\n",
    "    user_prompt = config.user_prompt.strip()\n",
    "\n",
    "    response_data = get_levels_from_response(response)\n",
    "\n",
    "    \n",
    "\n",
    "    final_usr= user_prompt.format(\n",
    "        Frame=frame,\n",
    "        level_1_values=response_data['level1_vals'],\n",
    "        level_1_rationale=response_data['level1_rats'],\n",
    "        level_2_values=response_data['level2_vals'],\n",
    "        level_2_rationale=response_data['level2_rats'],\n",
    "        level_3_values=response_data['level3_vals'],\n",
    "        level_3_rationale=response_data['level3_rats'],\n",
    "        app_level_2_values=response_data['app_level2_vals'],\n",
    "        app_level_3_values= response_data['app_level3_vals'],\n",
    "    )\n",
    "    msg = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": final_usr},\n",
    "    ]\n",
    "    #print_messages(msg)\n",
    "    return client.chat.completions.create(\n",
    "        model=config.model,\n",
    "        messages=msg,\n",
    "        temperature=config.temperature,\n",
    "        response_model=Feedback,\n",
    "        seed=config.seed\n",
    "    )\n",
    "\n",
    "def refine_response(config: InstructorChatCompletionConfig, response: Feedback, response0: dict, frame: str):\n",
    "\n",
    "    sys_prompt = config.system_prompt.strip()\n",
    "    user_prompt = config.user_prompt.strip()\n",
    "    response_data = get_levels_from_response(response0)\n",
    "    fdbk_str = \"\\n\".join(response.feedback)\n",
    "    final_usr= user_prompt.format(Frame=frame, level_1_values=response_data['level1_vals'], level_2_values=response_data['level2_vals'], level_3_values=response_data['level3_vals'],\n",
    "                                  feedback=fdbk_str)\n",
    "    msg = [{\"role\": \"system\", \"content\": sys_prompt},\n",
    "              {\"role\": \"user\", \"content\": final_usr}]\n",
    "    #print_messages(msg)\n",
    "    return client.chat.completions.create(\n",
    "        model=config.model,\n",
    "        messages=msg,\n",
    "        temperature=config.temperature,\n",
    "        response_model=CulturalValues,\n",
    "        seed=config.seed\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf4f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini=['fearmongering','women_valuation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "010f7127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping ableism\n",
      "skipping age_related_sexualization\n",
      "skipping ageism\n",
      "skipping appearance_based_discrimination\n",
      "skipping biased_judgement\n",
      "Stopping condition met for frame f6473.\n",
      "Stopping condition met for frame f1290.\n",
      "Stopping condition met for frame f1291.\n",
      "Stopping condition met for frame f2282.\n",
      "Stopping condition met for frame f4975.\n",
      "Stopping condition met for frame f6487.\n",
      "Stopping condition met for frame f6488.\n",
      "Stopping condition met for frame f7443.\n",
      "skipping coercion\n",
      "Stopping condition met for frame f5374.\n",
      "Stopping condition met for frame f667.\n",
      "Stopping condition met for frame f874.\n",
      "Stopping condition met for frame f3197.\n",
      "Stopping condition met for frame f3681.\n",
      "Stopping condition met for frame f4084.\n",
      "Stopping condition met for frame f5375.\n",
      "Stopping condition met for frame f5799.\n",
      "Stopping condition met for frame f5856.\n",
      "Stopping condition met for frame f5857.\n",
      "Stopping condition met for frame f6935.\n",
      "skipping conditional_respect\n",
      "Stopping condition met for frame f3542.\n",
      "Stopping condition met for frame f4517.\n",
      "Stopping condition met for frame f5264.\n",
      "Stopping condition met for frame f5743.\n",
      "Stopping condition met for frame f6008.\n",
      "Stopping condition met for frame f6010.\n",
      "skipping cultural_insensitivity\n",
      "skipping deflection\n",
      "skipping dehumanization_of_women\n",
      "skipping demeaning_aspirations\n",
      "skipping demonization\n",
      "skipping derogatory_labeling\n",
      "Stopping condition met for frame f519.\n",
      "skipping dismissing_women_s_rights\n",
      "skipping dismissiveness\n",
      "skipping disposability\n",
      "Stopping condition met for frame f6356.\n",
      "Stopping condition met for frame f6883.\n",
      "Stopping condition met for frame f6886.\n",
      "skipping disrespecting_sex_workers\n",
      "skipping divisiveness\n",
      "skipping double_standards\n",
      "skipping endorsing_marital_rape\n",
      "Stopping condition met for frame f1954.\n",
      "Stopping condition met for frame f5196.\n",
      "Stopping condition met for frame f1149.\n",
      "Stopping condition met for frame f1655.\n",
      "Stopping condition met for frame f2602.\n",
      "skipping enforced_gender_norms\n",
      "skipping exclusion\n",
      "Stopping condition met for frame f3967.\n",
      "skipping false_accusations\n",
      "skipping false_equivalence\n",
      "skipping fat_shaming\n",
      "skipping fearmongering\n",
      "Stopping condition met for frame f635.\n",
      "Stopping condition met for frame f3380.\n",
      "Stopping condition met for frame f344.\n",
      "Stopping condition met for frame f1362.\n",
      "Stopping condition met for frame f1405.\n",
      "Stopping condition met for frame f2381.\n",
      "Stopping condition met for frame f3787.\n",
      "Stopping condition met for frame f5414.\n",
      "skipping gender_essentialism\n",
      "Stopping condition met for frame f2202.\n",
      "Stopping condition met for frame f3922.\n",
      "Stopping condition met for frame f4263.\n",
      "Stopping condition met for frame f4351.\n",
      "Stopping condition met for frame f6315.\n",
      "skipping incest\n",
      "skipping intellectual_degradation\n",
      "skipping intersectional_prejudice\n",
      "skipping invalidating_women_s_experiences\n",
      "Stopping condition met for frame f662.\n",
      "Stopping condition met for frame f4280.\n",
      "Stopping condition met for frame f229.\n",
      "Stopping condition met for frame f756.\n",
      "Stopping condition met for frame f947.\n",
      "Stopping condition met for frame f3474.\n",
      "Stopping condition met for frame f4443.\n",
      "skipping menstruation_stigma\n",
      "skipping minimizing_feminist_efforts\n",
      "skipping misrepresentation\n",
      "skipping mistrust_in_women\n",
      "skipping misunderstanding_feminism\n",
      "Stopping condition met for frame f4107.\n",
      "Stopping condition met for frame f1286.\n",
      "Stopping condition met for frame f59.\n",
      "Stopping condition met for frame f1294.\n",
      "Stopping condition met for frame f1714.\n",
      "Stopping condition met for frame f2174.\n",
      "Stopping condition met for frame f2736.\n",
      "skipping objectification\n",
      "skipping ownership\n",
      "Stopping condition met for frame f366.\n",
      "Stopping condition met for frame f445.\n",
      "Stopping condition met for frame f4531.\n",
      "Stopping condition met for frame f7958.\n",
      "Stopping condition met for frame f5670.\n",
      "Stopping condition met for frame f7544.\n",
      "Stopping condition met for frame f5160.\n",
      "Stopping condition met for frame f2261.\n",
      "Stopping condition met for frame f2737.\n",
      "skipping patriarchal_control\n",
      "skipping pedophilia_exploitation\n",
      "skipping policing_women_s_bodies\n",
      "skipping possessiveness\n",
      "Stopping condition met for frame f3505.\n",
      "skipping promoting_infidelity\n",
      "skipping promoting_rape_culture\n",
      "Stopping condition met for frame f2153.\n",
      "Stopping condition met for frame f2704.\n",
      "Stopping condition met for frame f3676.\n",
      "Stopping condition met for frame f5238.\n",
      "Stopping condition met for frame f5577.\n",
      "Stopping condition met for frame f6054.\n",
      "skipping racism\n",
      "skipping reductionism\n",
      "skipping reverse_sexism\n",
      "skipping ridicule\n",
      "skipping scapegoating\n",
      "skipping sexist_pseudoscience\n",
      "skipping sexual_entitlement\n",
      "skipping sexual_harassment\n",
      "skipping sexual_innuendo\n",
      "skipping sexualization\n",
      "Stopping condition met for frame f5138.\n",
      "Stopping condition met for frame f689.\n",
      "Stopping condition met for frame f4022.\n",
      "Stopping condition met for frame f4227.\n",
      "Stopping condition met for frame f5111.\n",
      "Stopping condition met for frame f7010.\n",
      "Stopping condition met for frame f7651.\n",
      "skipping stereotyping\n",
      "skipping stigmatization\n",
      "Stopping condition met for frame f3366.\n",
      "Stopping condition met for frame f3971.\n",
      "Stopping condition met for frame f4012.\n",
      "Stopping condition met for frame f5848.\n",
      "Stopping condition met for frame f7478.\n",
      "skipping transactional_relationships\n",
      "skipping transphobia\n",
      "Stopping condition met for frame f4024.\n",
      "Stopping condition met for frame f1381.\n",
      "Stopping condition met for frame f2349.\n",
      "Stopping condition met for frame f2686.\n",
      "Stopping condition met for frame f3962.\n",
      "skipping trivializing_consent\n",
      "Stopping condition met for frame f1643.\n",
      "Stopping condition met for frame f4329.\n",
      "skipping trivializing_infidelity\n",
      "skipping trivializing_mental_health_issues\n",
      "skipping trivializing_oppression\n",
      "skipping trivializing_prostitution\n",
      "skipping trivializing_serious_issues\n",
      "skipping trivializing_sexual_assault\n",
      "Stopping condition met for frame f7412.\n",
      "Stopping condition met for frame f3951.\n",
      "Stopping condition met for frame f4178.\n",
      "Stopping condition met for frame f7818.\n",
      "skipping trivializing_women_s_issues\n",
      "skipping trivializing_women_s_sexual_satisfaction\n",
      "skipping undermining_women_s_capabilities\n",
      "skipping undermining_women_s_rights_movements\n",
      "skipping unrealistic_beauty_standards\n",
      "skipping victim_blaming\n",
      "skipping violence\n",
      "Stopping condition met for frame f1107.\n",
      "Stopping condition met for frame f4760.\n",
      "Stopping condition met for frame f6705.\n",
      "skipping women_subjugation\n",
      "skipping women_valuation\n",
      "Stopping condition met for frame f297.\n",
      "Stopping condition met for frame f540.\n",
      "Stopping condition met for frame f1188.\n",
      "Stopping condition met for frame f3441.\n",
      "Stopping condition met for frame f5186.\n",
      "Stopping condition met for frame f5267.\n",
      "Stopping condition met for frame f5610.\n",
      "Stopping condition met for frame f3911.\n",
      "Stopping condition met for frame f5998.\n"
     ]
    }
   ],
   "source": [
    "for f in sorted(os.listdir('final_frames')):\n",
    "    val_file=os.path.join('final_frames',f,'values.jsonl')\n",
    "    if os.path.isfile(val_file):\n",
    "        print(f\"skipping {f}\")\n",
    "        continue\n",
    "    '''if f not in ini:\n",
    "        continue'''\n",
    "    ffilename = os.path.join('final_frames', f, 'frames.jsonl')\n",
    "    problem_values=[]\n",
    "    for frame in read_jsonl(ffilename):\n",
    "        idf= frame['id']\n",
    "        frame = frame['frame']\n",
    "\n",
    "        response = generate_response(config, frame)\n",
    "        if response is None:\n",
    "            print(\"Intial response was None, skipping this frame {idf}.\")\n",
    "            continue\n",
    "        \n",
    "        history = History()\n",
    "\n",
    "        while True:\n",
    "            feedback = generate_feedback(feedback_config, response, frame)\n",
    "            if stop_condition(feedback, history):\n",
    "                print(f\"Stopping condition met for frame {idf}.\")\n",
    "                break\n",
    "            if feedback is None:\n",
    "                print(\"Feedback response was None, skipping this frame {idf}.\")\n",
    "                break\n",
    "            refined_response = refine_response(refine_config, feedback, response, frame)\n",
    "            if refined_response is None:\n",
    "                print(\"Refined response was None, skipping this frame {idf}.\")\n",
    "                break\n",
    "            history.add(response, feedback.feedback, refined_response)\n",
    "            response = refined_response\n",
    "        problem_values.append({\n",
    "            \"id\": idf,\n",
    "            \"frame\": frame,\n",
    "            \"response\": response.model_dump(),\n",
    "            \"history\": [step.model_dump() for step in history.history],\n",
    "        })\n",
    "        \n",
    "    write_jsonl(os.path.join('final_frames', f, 'values.jsonl'), problem_values)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ee3053",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_temp=[]\n",
    "problem_temp.append({\"id\": idf,\n",
    "            \"frame\": frame,\n",
    "            \"response\": response.model_dump(),\n",
    "            \"history\": [step.model_dump() for step in history.history],\n",
    "        })\n",
    "write_jsonl(os.path.join('values.jsonl'), problem_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e0e96",
   "metadata": {},
   "source": [
    "Confidence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475aa222",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ChatCompletionConfig:\n",
    "    seed: int\n",
    "    delay: int\n",
    "    model: str\n",
    "    max_tokens: int\n",
    "    temperature: float\n",
    "    system_prompt: str\n",
    "    user_prompt: str\n",
    "    response_format: dict | None = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_prompt(frame, value, rationale, user):\n",
    "    msg=[]\n",
    "    msg.append({\"role\":\"user\",\"content\": user.format(frame=frame, value=value, rationale=rationale)})\n",
    "    return msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "config_file_path = 'prompts/evaluate.yaml'\n",
    "with open(config_file_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    config = ChatCompletionConfig(**config)\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'], timeout=90)\n",
    "sys_prompt = config.system_prompt.strip()\n",
    "user_prompt= config.user_prompt.strip()\n",
    "msg=[{\"role\": \"system\", \"content\": sys_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d156aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for f in sorted(os.listdir('final_frames')):\n",
    "    val_file=os.path.join('final_frames',f,'values.jsonl')\n",
    "    for value in read_jsonl(val_file):\n",
    "        frame_id = value['id']\n",
    "        frame= value['frame']\n",
    "        l=value['response']['values']\n",
    "        if 'level_1_values' in l:\n",
    "            for x in l['level_1_values']:\n",
    "                msg.extend(make_user_prompt(msg, frame, x['level_1_value'], x['rationale'],user_prompt))\n",
    "                try:\n",
    "                    completion = client.chat.completions.create(\n",
    "                        model=config.model,\n",
    "                        messages=msg,\n",
    "                        temperature=config.temperature,\n",
    "                        seed=config.seed,\n",
    "                        response_format=config.response_format,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"API call failed for {frame_id}: {e}\")\n",
    "                    msg.pop()\n",
    "                    continue\n",
    "                msg.pop()\n",
    "                content = completion.choices[0].message.content\n",
    "                results.append({'id':frame_id, 'frame': frame, 'value': x['level_1_value'], 'rationale': x['rationale'], 'judgement':content['judge']})\n",
    "        \n",
    "        if 'level_2_values' in l:\n",
    "            for x in l['level_2_values']:\n",
    "                msg.extend(make_user_prompt(msg, frame, x['level_2_value'], x['rationale'],user_prompt))\n",
    "                try:\n",
    "                    completion = client.chat.completions.create(\n",
    "                        model=config.model,\n",
    "                        messages=msg,\n",
    "                        temperature=config.temperature,\n",
    "                        seed=config.seed,\n",
    "                        response_format=config.response_format,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"API call failed for {frame_id}: {e}\")\n",
    "                    msg.pop()\n",
    "                    continue\n",
    "                msg.pop()\n",
    "                content = completion.choices[0].message.content\n",
    "                results.append({'id':frame_id, 'frame': frame, 'value': x['level_2_value'], 'rationale': x['rationale'], 'judgement':content['judge']})\n",
    "        \n",
    "        if 'level_3_values' in l:\n",
    "            for x in l['level_3_values']:\n",
    "                msg.extend(make_user_prompt(msg, frame, x['level_3_value'], x['rationale'],user_prompt))\n",
    "                try:\n",
    "                    completion = client.chat.completions.create(\n",
    "                        model=config.model,\n",
    "                        messages=msg,\n",
    "                        temperature=config.temperature,\n",
    "                        seed=config.seed,\n",
    "                        response_format=config.response_format,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"API call failed for {frame_id}: {e}\")\n",
    "                    msg.pop()\n",
    "                    continue\n",
    "                msg.pop()\n",
    "                content = completion.choices[0].message.content\n",
    "                results.append({'id':frame_id, 'frame': frame, 'value': x['level_3_value'], 'rationale': x['rationale'], 'judgement':content['judge']})\n",
    "\n",
    "    print('Done with {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd27b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl('evaluations.jsonl', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "def",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
