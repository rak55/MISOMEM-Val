{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db36fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Dict, List, Any, Optional\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# AutoGen imports with Streamlit integration\n",
    "import autogen\n",
    "from autogen import ConversableAgent, GroupChat, GroupChatManager\n",
    "from autogen.io.websockets import IOWebsockets\n",
    "\n",
    "# Import your existing framework\n",
    "from structured_value_discovery import (\n",
    "    StructuredValueDiscoveryFramework, \n",
    "    FrameElement, \n",
    "    ValueStance,\n",
    "    ValueDiscovery,\n",
    "    DebateResults,\n",
    "    StructuredValueDiscoveryAgent,\n",
    "    StructuredDebateModerator,\n",
    "    VALUE_HIERARCHY\n",
    ")\n",
    "# Configure page\n",
    "st.set_page_config(\n",
    "    page_title=\"AutoGen Value Discovery Monitor\",\n",
    "    page_icon=\"ğŸ§ \",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f75f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoGenStreamlitInterface:\n",
    "    \"\"\"Interface between AutoGen agents and Streamlit UI\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.framework = StructuredValueDiscoveryFramework()\n",
    "        self.agents = []\n",
    "        self.moderator = None\n",
    "        self.group_chat = None\n",
    "        self.manager = None\n",
    "        \n",
    "        # Initialize session state\n",
    "        if 'messages' not in st.session_state:\n",
    "            st.session_state.messages = []\n",
    "        if 'agent_responses' not in st.session_state:\n",
    "            st.session_state.agent_responses = {}\n",
    "        if 'value_discoveries' not in st.session_state:\n",
    "            st.session_state.value_discoveries = {}\n",
    "        if 'debate_active' not in st.session_state:\n",
    "            st.session_state.debate_active = False\n",
    "        if 'current_frame' not in st.session_state:\n",
    "            st.session_state.current_frame = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13b0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_sidebar():\n",
    "    \"\"\"Setup sidebar with configuration and controls\"\"\"\n",
    "    st.sidebar.title(\"ğŸ§  AutoGen Value Discovery\")\n",
    "    st.sidebar.markdown(\"*Powered by Microsoft AutoGen*\")\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    \n",
    "    # API Configuration\n",
    "    st.sidebar.subheader(\"âš™ï¸ Configuration\")\n",
    "    api_key = st.sidebar.text_input(\n",
    "        \"OpenAI API Key\", \n",
    "        type=\"password\",\n",
    "        help=\"Required for running AutoGen agents\"\n",
    "    )\n",
    "    \n",
    "    if api_key:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "        st.sidebar.success(\"âœ… API Key configured\")\n",
    "    \n",
    "    # Model selection\n",
    "    model = st.sidebar.selectbox(\n",
    "        \"Model\",\n",
    "        [\"gpt-4o-2024-08-06\", \"gpt-4\", \"gpt-3.5-turbo\"],\n",
    "        help=\"Model for structured outputs (gpt-4o-2024-08-06 recommended)\"\n",
    "    )\n",
    "    \n",
    "    # Frame configuration\n",
    "    st.sidebar.subheader(\"ğŸ“ Debate Frame\")\n",
    "    frame_statement = st.sidebar.text_area(\n",
    "        \"Frame Statement\",\n",
    "        value=\"Attractive women deserve to be distrusted because they are prone to infidelity\",\n",
    "        height=100,\n",
    "        help=\"The controversial statement for value discovery\"\n",
    "    )\n",
    "    \n",
    "    problem_type = st.sidebar.selectbox(\n",
    "        \"Problem Type\",\n",
    "        [\n",
    "            \"Biased Judgement (Stereotyping)\",\n",
    "            \"Economic Prejudice\", \n",
    "            \"Gender Role Stereotyping\",\n",
    "            \"Racial Bias\",\n",
    "            \"Religious Intolerance\",\n",
    "            \"Age Discrimination\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return api_key, model, frame_statement, problem_type\n",
    "\n",
    "def create_autogen_agents(frame: FrameElement, model: str):\n",
    "    \"\"\"Create AutoGen agents for value discovery debate\"\"\"\n",
    "    \n",
    "    # Configuration for AutoGen\n",
    "    config_list = [\n",
    "        {\n",
    "            \"model\": model,\n",
    "            \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "            \"api_type\": \"openai\",\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    llm_config = {\n",
    "        \"config_list\": config_list,\n",
    "        \"temperature\": 0.7,\n",
    "        \"timeout\": 60,\n",
    "    }\n",
    "    \n",
    "    # Structured output configuration\n",
    "    structured_llm_config = {\n",
    "        **llm_config,\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"value_discovery_response\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"level_1_basic_values\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"values\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"value_name\": {\"type\": \"string\"},\n",
    "                                            \"justification\": {\"type\": \"string\"}\n",
    "                                        },\n",
    "                                        \"required\": [\"value_name\", \"justification\"]\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"level_2_value_categories\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"values\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"value_name\": {\"type\": \"string\"},\n",
    "                                            \"justification\": {\"type\": \"string\"}\n",
    "                                        },\n",
    "                                        \"required\": [\"value_name\", \"justification\"]\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"level_3_higher_order_values\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"values\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"value_name\": {\"type\": \"string\"},\n",
    "                                            \"justification\": {\"type\": \"string\"}\n",
    "                                        },\n",
    "                                        \"required\": [\"value_name\", \"justification\"]\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"hierarchical_integration\": {\"type\": \"string\"},\n",
    "                        \"main_argument\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"level_1_basic_values\", \"level_2_value_categories\", \"level_3_higher_order_values\", \"hierarchical_integration\", \"main_argument\"]\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create agents with personas\n",
    "    agents = []\n",
    "    \n",
    "    # Support Agent\n",
    "    support_agent = ConversableAgent(\n",
    "        name=\"Support_Agent\",\n",
    "        system_message=f\"\"\"You SUPPORT the frame's validity. \n",
    "\n",
    "{VALUE_HIERARCHY}\n",
    "\n",
    "FRAME: \"{frame.frame_statement}\"\n",
    "STANCE: SUPPORT\n",
    "\n",
    "You must discover and argue from Schwartz values that lead to SUPPORTING this frame.\n",
    "When providing value discovery, respond with valid JSON matching the schema.\n",
    "In follow-up responses, reference your discovered values while engaging in debate.\n",
    "\n",
    "Your persona: Conservative perspective valuing tradition and social order.\"\"\",\n",
    "        llm_config=structured_llm_config,\n",
    "        human_input_mode=\"NEVER\",\n",
    "        max_consecutive_auto_reply=2\n",
    "    )\n",
    "    agents.append(support_agent)\n",
    "    \n",
    "    # Contradict Agent  \n",
    "    contradict_agent = ConversableAgent(\n",
    "        name=\"Contradict_Agent\",\n",
    "        system_message=f\"\"\"You CONTRADICT the frame as harmful and wrong.\n",
    "\n",
    "{VALUE_HIERARCHY}\n",
    "\n",
    "FRAME: \"{frame.frame_statement}\" \n",
    "STANCE: CONTRADICT\n",
    "\n",
    "You must discover and argue from Schwartz values that lead to CONTRADICTING this frame.\n",
    "When providing value discovery, respond with valid JSON matching the schema.\n",
    "In follow-up responses, reference your discovered values while engaging in debate.\n",
    "\n",
    "Your persona: Progressive perspective championing equality and challenging discrimination.\"\"\",\n",
    "        llm_config=structured_llm_config,\n",
    "        human_input_mode=\"NEVER\", \n",
    "        max_consecutive_auto_reply=2\n",
    "    )\n",
    "    agents.append(contradict_agent)\n",
    "    \n",
    "    # Disregard Agent\n",
    "    disregard_agent = ConversableAgent(\n",
    "        name=\"Disregard_Agent\", \n",
    "        system_message=f\"\"\"You DISREGARD the frame as lacking merit/objectivity.\n",
    "\n",
    "{VALUE_HIERARCHY}\n",
    "\n",
    "FRAME: \"{frame.frame_statement}\"\n",
    "STANCE: DISREGARD\n",
    "\n",
    "You must discover and argue from Schwartz values that lead to DISREGARDING this frame.\n",
    "When providing value discovery, respond with valid JSON matching the schema.\n",
    "In follow-up responses, reference your discovered values while engaging in debate.\n",
    "\n",
    "Your persona: Analytical perspective focused on empirical evidence and logical reasoning.\"\"\",\n",
    "        llm_config=structured_llm_config,\n",
    "        human_input_mode=\"NEVER\",\n",
    "        max_consecutive_auto_reply=2\n",
    "    )\n",
    "    agents.append(disregard_agent)\n",
    "    \n",
    "    # Moderator\n",
    "    moderator = ConversableAgent(\n",
    "        name=\"Moderator\",\n",
    "        system_message=f\"\"\"You moderate value discovery debates about: \"{frame.frame_statement}\"\n",
    "\n",
    "Guide participants through:\n",
    "1. Structured value discovery (JSON format)\n",
    "2. Value-based debate and challenges\n",
    "3. Integration and final arguments\n",
    "\n",
    "Keep responses brief and focused on facilitating productive value-based discussion.\"\"\",\n",
    "        llm_config=llm_config,\n",
    "        human_input_mode=\"NEVER\",\n",
    "        max_consecutive_auto_reply=1\n",
    "    )\n",
    "    \n",
    "    return agents, moderator\n",
    "\n",
    "def setup_group_chat(agents, moderator):\n",
    "    \"\"\"Setup AutoGen group chat\"\"\"\n",
    "    all_agents = agents + [moderator]\n",
    "    \n",
    "    group_chat = GroupChat(\n",
    "        agents=all_agents,\n",
    "        messages=[],\n",
    "        max_round=20,\n",
    "        speaker_selection_method=\"round_robin\"\n",
    "    )\n",
    "    \n",
    "    manager = GroupChatManager(\n",
    "        groupchat=group_chat,\n",
    "        llm_config={\n",
    "            \"config_list\": [\n",
    "                {\n",
    "                    \"model\": \"gpt-4\",\n",
    "                    \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "                    \"api_type\": \"openai\",\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0.7,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return group_chat, manager\n",
    "\n",
    "def display_chat_interface():\n",
    "    \"\"\"Display the main chat interface using AutoGen integration\"\"\"\n",
    "    st.title(\"ğŸ§  AutoGen Value Discovery Debate\")\n",
    "    st.markdown(\"**AI agents discovering underlying values in controversial social frames**\")\n",
    "    \n",
    "    if st.session_state.current_frame:\n",
    "        st.info(f\"**Current Frame:** {st.session_state.current_frame.frame_statement}\")\n",
    "        st.caption(f\"Problem Type: {st.session_state.current_frame.problem_type}\")\n",
    "    \n",
    "    # Display chat messages\n",
    "    chat_container = st.container()\n",
    "    \n",
    "    with chat_container:\n",
    "        for message in st.session_state.messages:\n",
    "            speaker = message.get(\"name\", \"Unknown\")\n",
    "            content = message.get(\"content\", \"\")\n",
    "            \n",
    "            # Style messages based on speaker\n",
    "            if speaker == \"Moderator\":\n",
    "                with st.chat_message(\"assistant\", avatar=\"ğŸ­\"):\n",
    "                    st.markdown(f\"**{speaker}**: {content}\")\n",
    "            elif \"Support\" in speaker:\n",
    "                with st.chat_message(\"user\", avatar=\"âœ…\"):\n",
    "                    st.markdown(f\"**{speaker}**: {content}\")\n",
    "            elif \"Contradict\" in speaker:\n",
    "                with st.chat_message(\"user\", avatar=\"âŒ\"):\n",
    "                    st.markdown(f\"**{speaker}**: {content}\")\n",
    "            elif \"Disregard\" in speaker:\n",
    "                with st.chat_message(\"user\", avatar=\"âš ï¸\"):\n",
    "                    st.markdown(f\"**{speaker}**: {content}\")\n",
    "            else:\n",
    "                with st.chat_message(\"assistant\"):\n",
    "                    st.markdown(f\"**{speaker}**: {content}\")\n",
    "\n",
    "def display_value_analysis():\n",
    "    \"\"\"Display value analysis dashboard\"\"\"\n",
    "    if st.session_state.agent_responses:\n",
    "        st.subheader(\"ğŸ¯ Discovered Values\")\n",
    "        \n",
    "        # Create columns for each agent\n",
    "        agents = list(st.session_state.agent_responses.keys())\n",
    "        if len(agents) >= 3:\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            columns = [col1, col2, col3]\n",
    "            \n",
    "            for i, agent in enumerate(agents[:3]):\n",
    "                with columns[i]:\n",
    "                    st.markdown(f\"**{agent.replace('_Agent', '')}**\")\n",
    "                    \n",
    "                    response = st.session_state.agent_responses[agent]\n",
    "                    if isinstance(response, dict):\n",
    "                        # Display Level 1 values\n",
    "                        if \"level_1_basic_values\" in response:\n",
    "                            st.markdown(\"*Level 1 - Basic Values:*\")\n",
    "                            for val in response[\"level_1_basic_values\"].get(\"values\", []):\n",
    "                                st.markdown(f\"â€¢ **{val.get('value_name', 'N/A')}**\")\n",
    "                                st.caption(val.get('justification', 'No justification')[:100] + \"...\")\n",
    "                        \n",
    "                        # Display Level 2 values\n",
    "                        if \"level_2_value_categories\" in response:\n",
    "                            st.markdown(\"*Level 2 - Categories:*\")\n",
    "                            for val in response[\"level_2_value_categories\"].get(\"values\", []):\n",
    "                                st.markdown(f\"â€¢ **{val.get('value_name', 'N/A')}**\")\n",
    "                        \n",
    "                        # Display Level 3 values\n",
    "                        if \"level_3_higher_order_values\" in response:\n",
    "                            st.markdown(\"*Level 3 - Higher Order:*\")\n",
    "                            for val in response[\"level_3_higher_order_values\"].get(\"values\", []):\n",
    "                                st.markdown(f\"â€¢ **{val.get('value_name', 'N/A')}**\")\n",
    "\n",
    "def run_autogen_debate(frame: FrameElement, model: str):\n",
    "    \"\"\"Run the AutoGen debate\"\"\"\n",
    "    try:\n",
    "        # Create agents\n",
    "        agents, moderator = create_autogen_agents(frame, model)\n",
    "        group_chat, manager = setup_group_chat(agents, moderator)\n",
    "        \n",
    "        # Initial message\n",
    "        initial_message = f\"\"\"\n",
    "Welcome to the Value Discovery Debate!\n",
    "\n",
    "FRAME: \"{frame.frame_statement}\"\n",
    "PROBLEM TYPE: {frame.problem_type}\n",
    "\n",
    "Each agent must:\n",
    "1. First provide structured JSON value discovery\n",
    "2. Then engage in value-based debate\n",
    "3. Reference discovered values in arguments\n",
    "\n",
    "Support_Agent: Start with your structured value discovery for SUPPORTING this frame.\n",
    "\"\"\"\n",
    "        \n",
    "        # Clear previous messages\n",
    "        st.session_state.messages = []\n",
    "        st.session_state.agent_responses = {}\n",
    "        \n",
    "        # Progress placeholder\n",
    "        progress_placeholder = st.empty()\n",
    "        chat_placeholder = st.empty()\n",
    "        \n",
    "        # Custom message handling to update Streamlit\n",
    "        def message_handler(sender, message, recipient, silent):\n",
    "            \"\"\"Handle messages and update Streamlit interface\"\"\"\n",
    "            if not silent:\n",
    "                # Add to session state\n",
    "                st.session_state.messages.append({\n",
    "                    \"name\": sender.name if hasattr(sender, 'name') else str(sender),\n",
    "                    \"content\": message,\n",
    "                    \"timestamp\": datetime.now()\n",
    "                })\n",
    "                \n",
    "                # Try to parse JSON responses for value analysis\n",
    "                if hasattr(sender, 'name') and \"Agent\" in sender.name and sender.name != \"Moderator\":\n",
    "                    try:\n",
    "                        # Look for JSON in the message\n",
    "                        if message.strip().startswith('{') and message.strip().endswith('}'):\n",
    "                            parsed_response = json.loads(message)\n",
    "                            st.session_state.agent_responses[sender.name] = parsed_response\n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "                \n",
    "                # Update display\n",
    "                with chat_placeholder.container():\n",
    "                    display_chat_interface()\n",
    "        \n",
    "        # Register message handler\n",
    "        for agent in agents + [moderator]:\n",
    "            agent.register_reply([autogen.Agent, None], message_handler)\n",
    "        \n",
    "        # Start the conversation\n",
    "        with progress_placeholder:\n",
    "            st.info(\"ğŸš€ Starting AutoGen value discovery debate...\")\n",
    "        \n",
    "        # Run the group chat\n",
    "        chat_result = moderator.initiate_chat(\n",
    "            manager,\n",
    "            message=initial_message,\n",
    "            max_turns=15\n",
    "        )\n",
    "        \n",
    "        with progress_placeholder:\n",
    "            st.success(\"âœ… Debate completed!\")\n",
    "        \n",
    "        return chat_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"âŒ Error running debate: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main Streamlit app\"\"\"\n",
    "    \n",
    "    # Sidebar configuration\n",
    "    api_key, model, frame_statement, problem_type = setup_sidebar()\n",
    "    \n",
    "    # Control buttons\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    st.sidebar.subheader(\"ğŸ® Controls\")\n",
    "    \n",
    "    start_debate = st.sidebar.button(\n",
    "        \"ğŸš€ Start Value Discovery\",\n",
    "        disabled=not api_key or st.session_state.debate_active,\n",
    "        help=\"Start AutoGen value discovery debate\"\n",
    "    )\n",
    "    \n",
    "    clear_chat = st.sidebar.button(\n",
    "        \"ğŸ—‘ï¸ Clear Chat\",\n",
    "        disabled=st.session_state.debate_active,\n",
    "        help=\"Clear conversation history\"\n",
    "    )\n",
    "    \n",
    "    # Status\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    if st.session_state.debate_active:\n",
    "        st.sidebar.success(\"ğŸŸ¢ Debate in progress...\")\n",
    "    else:\n",
    "        st.sidebar.info(\"ğŸ”µ Ready to start\")\n",
    "    \n",
    "    st.sidebar.metric(\"Messages\", len(st.session_state.messages))\n",
    "    st.sidebar.metric(\"Agent Responses\", len(st.session_state.agent_responses))\n",
    "    \n",
    "    # Handle button clicks\n",
    "    if start_debate and frame_statement.strip():\n",
    "        frame = FrameElement(\n",
    "            frame_statement=frame_statement.strip(),\n",
    "            problem_type=problem_type\n",
    "        )\n",
    "        st.session_state.current_frame = frame\n",
    "        st.session_state.debate_active = True\n",
    "        \n",
    "        # Run debate\n",
    "        result = run_autogen_debate(frame, model)\n",
    "        \n",
    "        st.session_state.debate_active = False\n",
    "    \n",
    "    if clear_chat:\n",
    "        st.session_state.messages = []\n",
    "        st.session_state.agent_responses = {}\n",
    "        st.session_state.current_frame = None\n",
    "        st.rerun()\n",
    "    \n",
    "    # Main interface\n",
    "    tab1, tab2 = st.tabs([\"ğŸ’¬ Live Debate\", \"ğŸ¯ Value Analysis\"])\n",
    "    \n",
    "    with tab1:\n",
    "        display_chat_interface()\n",
    "    \n",
    "    with tab2:\n",
    "        display_value_analysis()\n",
    "    \n",
    "    # Auto-refresh during active debate\n",
    "    if st.session_state.debate_active:\n",
    "        time.sleep(1)\n",
    "        st.rerun()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
